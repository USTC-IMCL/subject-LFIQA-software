# subject-LFIQA-software Version 2.0

This is IMCL software for subjective light field image quality assessment. It has been remade with Qt (PySide6).

## How to Run
As the project is implemented with Python, you may run it from the scripts. But I recommend to use the compiled binary file that we released.  

If you want a passive light field image feature (i.e. passive view changing or passive refocusing), then make sure you have installed the ffmpeg in your system. For windows system you can download the portable **ffmpeg [here](https://github.com/GyanD/codexffmpeg/releases/tag/2023-09-29-git-40aa451154)**. The ffmpeg path should be added into system environment.

1. Run from scripts
   
   Python 3.9+ is recomended.
   Before running it some python modules should be installed. 
   
   ```
   pip install PySide6 xlsxwriter xlsxreader openpyxl numpy opencv-python
   ```
   Download and unpack the source code. Enter the folder and run it with
   
   ```
   python LFIQoE.py
   ```
   
2. (Recommended) Alternatively, you can download the [binary file](https://github.com/USTC-IMCL/subject-LFIQA-software/releases/tag/V2.0). Put it to anywhere you like and double click it.


## Data Preparation

Before Config your own experiment, you need to prepare your own data. The folders are organized as below:

```
├── your light field name 1
│   └── Origin
│   └── distorted
│     └── distortion_type_1
|        └── 1
|        └── 2
|        └── 3
|        └── 4
|        └── 5
│     └── distortion_type_2
│     └── distortion_type_3
│     └── distortion_type_4
    ......
├── your light field name 2
│   └── Origin
│   └── distorted
.......
```
The Origin folder contains origin light field views. Each distorted type has 5 levels (it is fixed in this version, see konwn issue section).

In each folder, e.g. the Origin or the distortion_type_2/1, the views are named in x_y.png or h_w.png format. The x/y (w/h) represents col index and row index respectively in the angular domain. The number of the angular index should be continuous but **it does not need to start from 0**. Also, any formats including png, jpg, bmp or ppm are acceptable. But we do not consider the bit depth greater than 8.

**If you want a refocusing feature, please put the lambda file and the depth map in each folder. The lambda file is only for the dense light field image. The module for sparse light field images need to be further implemented.**

## Configuration
Click the Project->New button to create a new experiment. 

![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/533d0341-1a55-4f6b-8805-35e58cb802f5)

Use the Json file to configure your experiment.

## Preprocessing

Click the Run -> Preprocessing to generate images or videos for your experiments.

![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/9382d20f-a4d3-400b-95de-130e99f8b8b4)

Note that now the refocusing module only supports light field images captured by Lytro. But the extension for different rigs will be supported in the future.

If you use a passive feature for your experiment, you may find a .mp4 file in the folder. It is generated by concating show views. To make sure a **view synchronization**, we stiching the comparing views into one single frame and compress it with ffmpeg **losslessly**. The views order or the focusing moving order is fixed now (but can be extended).

## How to evaluate

This section explains the operation to evaluate the light field image.

0. Start your training or test

1.Use the Run -> Start training or Run -> Start test to start your evaluation experiment. Note that the training stage won't record your subjects' name -- the training stage should try to teach the subjects, not to record their socres.


2. Active view changing
   
   Use a right click (any position is fine) to start the view changing. Then you can change the view by moving mouse. Note that we use a right click to "wake up" the view changing instead of using the hover directly. This avoids subjects to take a border view as the first-glance view and can make sure that each subject starts from the same view (e.g. the center view).
    
3. Active refocusing
   
  
  Use a left clicing (any positin within the view) to select where you want to focus. This will close the active view changing.
      
3. Passive feature
   
   Just left clicking the view then the video begins playing.

4. Pair comparison
   
   Use a left or right arrow to select the better one. Note once you press the key, it records your choice and show the next page.

5. Scoring
   
   Use left or right arrow te select the scring table and the number key to offer you evaluation score.
   
   ![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/c169c84d-11d6-4247-acec-69ebaa872fab)

6. Next page
   
   Use enter key to get next page when you have finished exploring the light field immage (except the pair-wise comparison mode).

## Postprocessing

  Click the Run -> Post Processing button to start the post processing. The project will record all your subjects so you just need to click the button. It will calculate the PLCC between each subjects and others' mean scores.

## Compile to exe file

   If you want to revise the source code and compile it manually, use the pyinstaller:

   ```
   pyinstall --onefile -w -p ./UI -p ./Widgets --add-data "your/path/to/ffmpeg;./" LFIQoE.py
   ```

## Acknowledgement

We follow the BSD license.

Any problem or quesition please email me: zsy7788@mail.ustc.edu.cn. Any new issue for this project is welcome.
