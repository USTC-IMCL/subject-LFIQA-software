# subject-LFIQA-software Version 1.1

This is IMCL software for subjective light field image quality assessment. It has been remade with Qt (PySide6).

## How to Run
As the project is implemented with Python, you may run it from the scripts. But I recommend to use the compiled binary file that we released.

If you want a passive light field image feature (i.e. passive view changing or passive refocusing), then make sure you have installed the ffmpeg in your system. For windows system you can download the portable **ffmpeg [here](https://github.com/GyanD/codexffmpeg/releases/tag/2023-09-29-git-40aa451154)**. The ffmpeg path should be added into system environment.

1. Run from scripts
   
   Python 3.9+ is recomended.
   Before running it some python modules should be installed. 
   
   ```
   pip install PySide6 xlsxwriter xlsxreader openpyxl numpy opencv-python
   ```
   Download and unpack the source code. Enter the folder and run it with
   
   ```
   python LFIQoE.py
   ```
   
2. Alternatively, you can download the [binary file](https://github.com/USTC-IMCL/subject-LFIQA-software/releases/). Put it to anywhere you like and double click it.


## Data Preparation

Before Config your own experiment, you need to prepare your own data. The folders are organized as below:

```
├── your light field name 1
│   └── Origin
│   └── distorted
│     └── distortion_type_1
|        └── 1
|        └── 2
|        └── 3
|        └── 4
|        └── 5
│     └── distortion_type_2
│     └── distortion_type_3
│     └── distortion_type_4
    ......
├── your light field name 2
│   └── Origin
│   └── distorted
.......
```
The Origin folder contains origin light field views. Each distorted type has 5 levels (it is fixed in this version, see konwn issue section).

In each folder, e.g. the Origin or the distortion_type_2/1, the views are named in x_y.png or h_w.png format. The x/y (w/h) represents col index and row index respectively in the angular domain. The number of the angular index should be continuous but **it does not need to start from 0**. Also, any formats including png, jpg, bmp or ppm are acceptable. But we do not consider the bit depth greater than 8.

**If you want a refocusing feature, please put the lambda file and the depth map in each folder. The lambda file is only for the dense light field image. The module for sparse light field images need to be further implemented.**

## Configuration
Click the NewExperimentConfig button to set a new experiment. 

![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/29f5d155-41de-4b44-b25c-5dc804581e8f)

Use Add new LFI button to add new test light field images. The training and testing stages are seperated but they follow the same configuration flow.

![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/76327d40-c189-41b2-8cfe-d69d00377680)

The software then analyze the folders to get the angular size and the distortion types. Finally you should specify your experiment setting as below:

![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/bc119958-0256-47f8-993c-558d3f839d02)

You may select 2D display or 3D display. The view changing or refocusing features can be active, passive or None. But at lease you need to choose one (thus they can not be both None). 

The pair comparison is also supported but you need to tell the software the comparison list by a json file. The example can be found [here](https://github.com/USTC-IMCL/subject-LFIQA-software/blob/main/Widgets/PairWise.json). 

The output file can be in CSV or XLSX format. **Note that you do not need to install the office excel in your machine**. You can just save the result as an xlsx file and open it with your browser (e.g. with google doc plugin).

Finally click the Finish button and name your project.

## Preprocessing

After finishing the cofiguration, you can choose preprocess the data immediately or skip it. The software always checks the preprocessing when start the evaluation experiment.

The preprocessing will take a lot time in the background so please wait patiently. Do not close the software.

You can check the preprocessing results in the view folder. It looks like the following:

![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/bb8283a4-a87c-4945-a8e8-5da524d71dd8)

The show_views and views_refocusing folders contain the preprocessing results.

If you use a passive feature for your experiment, you may find a .mp4 file in the folder. It is generated by concating show views. To make sure a **view synchronization**, we stiching the comparing views into one single frame and compress it with ffmpeg **losslessly**. The views order or the focusing moving order is fixed now (but can be extended).

## How to evaluate

This section explains the operation to evaluate the light field image.

1. Active view changing
   

   Use a right click (any position is fine) to start the view changing. Then you can change the view by moving mouse. Note that we use a right click to "wake up" the view changing instead of using the hover directly. This avoids subjects to take a border view as the first-glance view and can make sure that each subject starts from the same view (e.g. the center view).
    
3. Active refocusing
   
  
  Use a left clicing (any positin within the view) to select where you want to focus. This will close the active view changing.
      
3. Passive feature
   
   Just left clicking the view then the video begins playing.

4. Pair comparison
   
   Use a left or right arrow to select the better one. Note once you press the key, it records your choice and show the next page.

5. Scoring
   
   Use left or right arrow te select the scring table and the number key to offer you evaluation score.
   
   ![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/c169c84d-11d6-4247-acec-69ebaa872fab)

6. Next page
   
   Use enter key to get next page when you have finished exploring the light field immage (except the pair-wise comparison mode).

## Postprocessing
Click the Post Processing button to start the post processing. Two file selection dialogs will be open. Here are tow steps:

1. Choose the folder that contains your subject file. Currently it is the folder you put the binary software.

2. Choose your configuration file.

Then the software will extract info from all the subjects results and calculate PLCC for each subject. The results will be stored in outlier_result.csv or outlier_result.xlsx. The format depends on your experiment setting.

## Known issues

Here we list the known issues that should be solved or improved in the future.

1. Configuration guides. Currently nothing happend if there is anything wrong duiring the configuration. A pop-out window is needed to guide the user if there are problems with the configuration.

2. Configuration with json. The interface is not released this version. Actually you can find a ***Previous*** button when configuring the trainning. Its previous page looks like the following:

   ![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/0b05d772-9314-404a-9396-fbc955ec3566)

   It is hidden currently. (Thus each experiment should be configured manually.)
   

3. The number of distortion levels is fixed to 5. The distortion levels should be denoted by the experiment designer.

4. Refocusing module only works for **Lytro light field images**. But it can be easily extended. As shown below,

   ![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/c8fb5153-6dec-48d1-80d0-e67479f48880)

   First we detect the views paths of the origin light field images and the distorted ones. The lambda file which contains Lytro camera information and the depth map from Lytro desktop software are adopted to generate all possible refocusing results for each light field images, if the refocusing feature is required. Then with the calculated results we 'stitch' them into one singel picture. If a passive feature is needed, the ffmpeg is used to concat these pictures as frames into one .mp4 fiel losslessly.

   We can see that this working flow can be extened to any light field images if we have an appropriate refocusing algorithm. Some other ways may also help, e.g. make a plugin interface to let users use their own refocusing script, or just let users specify the refocusing results path manually.

5. Output folders are fixed to the folder where exe file is put. It should be specified by the users.

6. Preprocessing after configuration. If one chooses ***preprocessing*** immediately after clicling the ***Finish** button, he/she needs to select the saved project file first.

7. Post processing file selection. The saved csv or excel files paths should be included in the project file. Then the user just need to select the project file only.

8. Bug for None-refocusing. 

## Acknowledgement

Any problem or quesition please email me: zsy7788@mail.ustc.edu.cn. Any new issue for this project is welcome.
