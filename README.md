# subject-LFIQA-software Version 1.0

This is IMCL software for subjective light field image quality assessment. It has been remade with Qt (PySide6).

## How to Run
As the project is implemented with Python, you may run it from the scripts. But I recommend to use the compiled binary file that we released.

If you want a passive light field image feature (i.e. passive view changing or passive refocusing), then make sure you have installed the ffmpeg in your system. For windows system you can download the portable **ffmpeg [here](https://github.com/GyanD/codexffmpeg/releases/tag/2023-09-29-git-40aa451154)**.

1. Run from scripts
   
   Python 3.9+ is recomended.
   Before running it some python modules should be installed. 
   
   ```
   pip install PySide6 xlsxwriter openpyxl numpy opencv-python
   ```
   Download and unpack the source code. Enter the folder and run it with
   
   ```
   python LFIQoE.py
   ```
   
2. Alternatively, you can download the [binary file](https://github.com/USTC-IMCL/subject-LFIQA-software/releases/download/V1.0/LFIQoE.exe). Put it to anywhere you like and double click it.


## Data Preparation

Before Config your own experiment, you need to prepare your own data. The folders are organized as below:

```
├── your light field name 1
│   └── Origin
│   └── distorted
│     └── distortion_type_1
|        └── 1
|        └── 2
|        └── 3
|        └── 4
|        └── 5
│     └── distortion_type_2
│     └── distortion_type_3
│     └── distortion_type_4
    ......
├── your light field name 2
│   └── Origin
│   └── distorted
.......
```
The Origin folder contains origin light field views. Each distorted type has 5 levels (it is fixed in this version, see konwn issue section).

In each folder, e.g. the Origin or the distortion_type_2/1, the views are named in x_y.png or h_w.png format. The x/y (w/h) represents col index and row index respectively in the angular domain. The number of the angular index should be continuous but **it does not need to start from 0**. Also, any formats including png, jpg, bmp or ppm are acceptable. But we do not consider the bit depth greater than 8.

**If you want a refocusing feature, please put the lambda file and the depth map in each folder. The lambda file is only for the dense light field image. The module for sparse light field images need to be further implemented.**

## Configuration
Click the NewExperimentConfig button to set a new experiment. 

![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/29f5d155-41de-4b44-b25c-5dc804581e8f)

Use Add new LFI button to add new test light field images. The training and testing stages are seperated but they follow the same configuration flow.

![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/76327d40-c189-41b2-8cfe-d69d00377680)

The software then analyze the folders to get the angular size and the distortion types. Finally you should specify your experiment setting as below:

![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/bc119958-0256-47f8-993c-558d3f839d02)

You may select 2D display or 3D display. The view changing or refocusing features can be active, passive or None. But at lease you need to choose one (thus they can not be both None). 

The pair comparison is also supported but you need to tell the software the comparison list by a json file. The example can be found [here](https://github.com/USTC-IMCL/subject-LFIQA-software/blob/main/Widgets/PairWise.json). 

The output file can be in CSV or XLSX format. **Note that you do not need to install the office excel in your machine**. You can just save the result as an xlsx file and open it with your browser (e.g. with google doc plugin).

Finally click the Finish button and name your project.

## Preprocessing

After finishing the cofiguration, you can choose preprocess the data immediately or skip it. The software always checks the preprocessing when start the evaluation experiment.

The preprocessing will take a lot time in the background so please wait patiently. Do not close the software.

You can check the preprocessing results in the view folder. It looks like the following:

![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/bb8283a4-a87c-4945-a8e8-5da524d71dd8)

The show_views and views_refocusing folders contain the preprocessing results.

If you use a passive feature for your experiment, you may find a .mp4 file in the folder. It is generated by concating show views. To make sure a **view synchronization**, we stiching the comparing views into one single frame and compress it with ffmpeg **losslessly**. The views order or the focusing moving order is fixed now (but can be extended).

## How to evaluate

This section explains the operation to evaluate the light field image.

1. Active view changing
   
   Use a right click (any position is fine) to start the view changing. Then you can change the view by moving mouse. Note that we use a right click to "wake up" the view changing instead of using the hover directly. This avoids subjects to take a border view as the first-glance view and can make sure that each subject starts from the same view (e.g. the center view).
    
2. Active refocusing
   
  Use a left clicing (any positin within the view) to select where you want to focus. This will close the active view changing.
      
3. Passive feature
   
  Just left clicking the view then the video begins playing.

4. Pair comparison
   
   Use a left or right arrow to select the better one. Note once you press the key, it records your choice and show the next page.

5. Scoring
   
   Use left or right arrow te select the scring table and the number key to offer you evaluation score.
   
   ![image](https://github.com/USTC-IMCL/subject-LFIQA-software/assets/9655283/c169c84d-11d6-4247-acec-69ebaa872fab)

6. Next page
   
   Use enter key to get next page when you have finished exploring the light field immage (except the pair-wise comparison mode).
   
## Known issues & Discussions

Coming soon...

## Acknowledgement

Any problem or quesition please email me: zsy7788@mail.ustc.edu.cn. Any new issue for this project is welcome.
